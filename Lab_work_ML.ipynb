{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcxUHfpL4fbDgP1KxhU9Ub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek1shrivastava/Machine-learning/blob/main/Lab_work_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIf-sCAVxE5d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Implement and demonstrate the FIND-S algorithm for finding the most specific hypothesis based on a\n",
        "given set of training data samples. Read the training data from a .CSV file **bold text**"
      ],
      "metadata": {
        "id": "HqY7Y_KufnYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# to read the data in the csv file\n",
        "data = pd.read_csv(\"find_s.csv\")\n",
        "print(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_f-pJxqf3Z3",
        "outputId": "649d3c6d-515f-4c19-a386-a4ca4fb180bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Time Weather Temperature Company Humidity    Wind Goes\n",
            "0  Morning   Sunny        Warm     Yes     Mild  Strong  Yes\n",
            "1  Evening   Rainy        Cold      No     Mild  Normal   No\n",
            "2  Morning   Sunny    Moderate     Yes   Normal  Normal  Yes\n",
            "3  Evening   Sunny        Cold     Yes     High  Strong  Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making an array of all the attributes\n",
        "d = np.array(data)[:, :-1]\n",
        "print(\" \\n The attributes are: \", d)\n",
        "#\n",
        "# segragating the target that has positive and negative examples\n",
        "target = np.array(data)[:, -1]\n",
        "print(\"\\n The target is: \", target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z6QSqg0iLD-",
        "outputId": "d3015826-80fe-4aca-a4a1-2a1e9f070f45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " The attributes are:  [['Morning' 'Sunny' 'Warm' 'Yes' 'Mild' 'Strong']\n",
            " ['Evening' 'Rainy' 'Cold' 'No' 'Mild' 'Normal']\n",
            " ['Morning' 'Sunny' 'Moderate' 'Yes' 'Normal' 'Normal']\n",
            " ['Evening' 'Sunny' 'Cold' 'Yes' 'High' 'Strong']]\n",
            "\n",
            " The target is:  ['Yes' 'No' 'Yes' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# training function to implement find-s algorithm\n",
        "def train(c, t):\n",
        "    for i, val in enumerate(t):\n",
        "        if val == \"Yes\":\n",
        "            specific_hypothesis = c[i].copy()\n",
        "            print(\"specific_hypothesis\",specific_hypothesis)\n",
        "            break\n",
        "\n",
        "    for i, val in enumerate(c):\n",
        "        if t[i] == \"Yes\":\n",
        "            print(\"As\", i)\n",
        "            for x in range(len(specific_hypothesis)):\n",
        "                print(x)\n",
        "                if val[x] != specific_hypothesis[x]:\n",
        "                    specific_hypothesis[x] = '?'\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "    return specific_hypothesis\n",
        "\n",
        "\n",
        "#obtaining the final hypothesis\n",
        "print(\"n The final hypothesis is:\", train(d, target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPaw_rWeiQPF",
        "outputId": "88ba10b9-bf2e-4a69-c14f-d07874e22e59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "specific_hypothesis ['Morning' 'Sunny' 'Warm' 'Yes' 'Mild' 'Strong']\n",
            "As 0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "As 2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "As 3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "n The final hypothesis is: ['?' 'Sunny' '?' 'Yes' '?' '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. For a given set of training data examples stored in a .CSV file, implement and demonstrate the CandidateElimination algorithm to output a description of the set of all hypotheses consistent with the training\n",
        "examples **bold text**\n"
      ],
      "metadata": {
        "id": "11tinsCBiVTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7_6nEbeTfmRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def candidate_elimination(Trainigdata):\n",
        "    data = pd.read_csv(\"/content/training_data.csv\")\n",
        "    concepts = data.iloc[:, :-1].values\n",
        "    target = data.iloc[:, -1].values\n",
        "\n",
        "    def more_general(h1, h2):\n",
        "        for x, y in zip(h1, h2):\n",
        "            if x != '?' and (x != y and x != 'Ã˜'):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def generalize_S(example, S):\n",
        "        new_S = S.copy()\n",
        "        for i in range(len(S)):\n",
        "            if S[i] != example[i]:\n",
        "                new_S[i] = '?'\n",
        "        return new_S\n",
        "\n",
        "    def specialize_G(hypothesis, example):\n",
        "        specializations = []\n",
        "        for i in range(len(hypothesis)):\n",
        "            if hypothesis[i] == '?':\n",
        "                for value in domains[i]:\n",
        "                    if value != example[i]:\n",
        "                        new_hypothesis = list(hypothesis)\n",
        "                        new_hypothesis[i] = value\n",
        "                        specializations.append(new_hypothesis)\n",
        "        return specializations\n",
        "\n",
        "    # Get domains of attributes for specialization\n",
        "    domains = [list(set(data[col])) for col in data.columns[:-1]]\n",
        "\n",
        "    S = list(concepts[0])\n",
        "    G = [['?' for _ in range(len(S))]]\n",
        "\n",
        "    for i, example in enumerate(concepts):\n",
        "        if target[i] == \"Yes\":\n",
        "            G = [g for g in G if more_general(g, example)]\n",
        "            S = generalize_S(example, S)\n",
        "        else:\n",
        "            G_new = []\n",
        "            for g in G:\n",
        "                if more_general(g, example):\n",
        "                    G_new += specialize_G(g, example)\n",
        "            G = [g for g in G_new if any(more_general(g, s) for s in [S])]\n",
        "\n",
        "    print(\"\\nFinal Specific Hypothesis (S):\", S)\n",
        "    print(\"Final General Hypotheses (G):\", G)\n",
        "\n",
        "# Example usage\n",
        "candidate_elimination('training_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TLyWfmFiqH_",
        "outputId": "09c33075-52b5-4ca9-9ad7-1ba380802609"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Specific Hypothesis (S): ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n",
            "Final General Hypotheses (G): [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cq2RlmBpkND_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a program to demonstrate the working of the decision tree based ID3 algorithm. Use an appropriate\n",
        "data set for building the decision tree and apply this knowledge to classify a new sample **bold text**"
      ],
      "metadata": {
        "id": "Ckv5lrH5liSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# Load PlayTennis dataset\n",
        "data = {\n",
        "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
        "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
        "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK103Mg9kfVF",
        "outputId": "032204ff-e077-406b-ccaf-f6c3b2454ee8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Outlook Temperature Humidity    Wind PlayTennis\n",
            "0      Sunny         Hot     High    Weak         No\n",
            "1      Sunny         Hot     High  Strong         No\n",
            "2   Overcast         Hot     High    Weak        Yes\n",
            "3       Rain        Mild     High    Weak        Yes\n",
            "4       Rain        Cool   Normal    Weak        Yes\n",
            "5       Rain        Cool   Normal  Strong         No\n",
            "6   Overcast        Cool   Normal  Strong        Yes\n",
            "7      Sunny        Mild     High    Weak         No\n",
            "8      Sunny        Cool   Normal    Weak        Yes\n",
            "9       Rain        Mild   Normal    Weak        Yes\n",
            "10     Sunny        Mild   Normal  Strong        Yes\n",
            "11  Overcast        Mild     High  Strong        Yes\n",
            "12  Overcast         Hot   Normal    Weak        Yes\n",
            "13      Rain        Mild     High  Strong         No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate entropy\n",
        "def entropy(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts=True)\n",
        "    entropy = -sum([(counts[i]/sum(counts)) * math.log2(counts[i]/sum(counts)) for i in range(len(elements))])\n",
        "    return entropy\n",
        "\n",
        "# Function to calculate Information Gain\n",
        "def info_gain(data, attr, target_name):\n",
        "    total_entropy = entropy(data[target_name])\n",
        "    vals, counts = np.unique(data[attr], return_counts=True)\n",
        "    weighted_entropy = sum([(counts[i]/sum(counts)) * entropy(data[data[attr] == vals[i]][target_name]) for i in range(len(vals))])\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "# ID3 Algorithm\n",
        "def ID3(data, originaldata, features, target_attribute_name, parent_class=None):\n",
        "    # If all target values have same class, return class\n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]\n",
        "\n",
        "    # If dataset is empty, return mode target attribute of original data\n",
        "    elif len(data) == 0:\n",
        "        return np.unique(originaldata[target_attribute_name])[\n",
        "            np.argmax(np.unique(originaldata[target_attribute_name], return_counts=True)[1])]\n",
        "\n",
        "    # If no features left, return parent class\n",
        "    elif len(features) == 0:\n",
        "        return parent_class\n",
        "\n",
        "    # Recursive case\n",
        "    else:\n",
        "        # Set default parent class as mode target feature of current node\n",
        "        parent_class = np.unique(data[target_attribute_name])[\n",
        "            np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
        "\n",
        "        # Choose the best attribute\n",
        "        item_values = [info_gain(data, feature, target_attribute_name) for feature in features]\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "\n",
        "        # Build tree\n",
        "        tree = {best_feature: {}}\n",
        "        feature_values = np.unique(data[best_feature])\n",
        "\n",
        "        for value in feature_values:\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "            subtree = ID3(sub_data, originaldata, [feat for feat in features if feat != best_feature],\n",
        "                          target_attribute_name, parent_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "        return tree\n",
        "\n",
        "# Classification function\n",
        "def classify(query, tree, default=None):\n",
        "    for key in list(query.keys()):\n",
        "        if key in tree.keys():\n",
        "            try:\n",
        "                result = tree[key][query[key]]\n",
        "            except:\n",
        "                return default\n",
        "            result = tree[key][query[key]]\n",
        "            if isinstance(result, dict):\n",
        "                return classify(query, result)\n",
        "            else:\n",
        "                return result\n",
        "\n",
        "# Build the tree\n",
        "import numpy as np\n",
        "features = df.columns[:-1].tolist()\n",
        "tree = ID3(df, df, features, 'PlayTennis')\n",
        "\n",
        "# Print the decision tree\n",
        "import pprint\n",
        "print(\"Decision Tree:\")\n",
        "pprint.pprint(tree)\n",
        "\n",
        "# Classify a new sample\n",
        "sample = {'Outlook': 'Sunny', 'Temperature': 'Cool', 'Humidity': 'High', 'Wind': 'Strong'}\n",
        "prediction = classify(sample, tree)\n",
        "print(\"\\nNew Sample:\", sample)\n",
        "print(\"Predicted Class:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40Zv1qqukv-8",
        "outputId": "b224fc10-4263-495d-de3d-0195b945f8fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree:\n",
            "{'Outlook': {'Overcast': 'Yes',\n",
            "             'Rain': {'Wind': {'Strong': 'No', 'Weak': 'Yes'}},\n",
            "             'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}}}\n",
            "\n",
            "New Sample: {'Outlook': 'Sunny', 'Temperature': 'Cool', 'Humidity': 'High', 'Wind': 'Strong'}\n",
            "Predicted Class: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PDO2EsAxxKM9"
      }
    }
  ]
}